{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f11270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d0e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Little Prince\n",
      "written and illustrated by\n",
      "Antoi\n",
      "90305\n"
     ]
    }
   ],
   "source": [
    "f = open('TheLittlePrince.txt',encoding='utf-8')\n",
    "prince = f.read()\n",
    "print(prince[:50])\n",
    "print(len(prince))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710dab3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TOKENIZE\n",
    "princetokens = nltk.word_tokenize(prince)\n",
    "len(princetokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd75c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21198"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOWER\n",
    "princewords = [w.lower() for w in princetokens]\n",
    "len(princewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74fcf234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". \t 1567\n",
      ", \t 1036\n",
      "the \t 971\n",
      "'' \t 715\n",
      "`` \t 549\n",
      "i \t 544\n",
      "to \t 462\n",
      "a \t 409\n",
      "and \t 348\n",
      "of \t 336\n"
     ]
    }
   ],
   "source": [
    "## FREQUENCY\n",
    "from nltk import FreqDist\n",
    "ndist=FreqDist(princewords)\n",
    "nitems = ndist.most_common(10)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36b6f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', 1567)\n",
      "(',', 1036)\n",
      "('the', 971)\n",
      "(\"''\", 715)\n",
      "('``', 549)\n",
      "('i', 544)\n",
      "('to', 462)\n",
      "('a', 409)\n",
      "('and', 348)\n",
      "('of', 336)\n"
     ]
    }
   ],
   "source": [
    "topkeys = ndist.most_common(10)\n",
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d00c84d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', 0.07392206811963392)\n",
      "(',', 0.04887253514482498)\n",
      "('the', 0.045806208132842724)\n",
      "(\"''\", 0.033729597131804887)\n",
      "('``', 0.025898669685819418)\n",
      "('i', 0.025662798377205396)\n",
      "('to', 0.021794508915935467)\n",
      "('a', 0.01929427304462685)\n",
      "('and', 0.016416643079535807)\n",
      "('of', 0.015850551938862156)\n"
     ]
    }
   ],
   "source": [
    "#normalized frequency\n",
    "numwords = len(princewords)\n",
    "topkeysnorm=[(word, freq/numwords) for (word,freq) in topkeys]\n",
    "for pair in topkeysnorm:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a339149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "## NON-ALPHA FILTER\n",
    "pattern = re.compile('^[^a-z]+$')\n",
    "nonAlphaMatch = pattern.match('**')\n",
    "#  if it matched, print a message\n",
    "if nonAlphaMatch:\n",
    "    print ('matched non-alphabetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92987301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6062dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'little', 'prince', 'written', 'and', 'illustrated', 'by', 'antoine', 'de', 'saint', 'exupéry', 'translated', 'from', 'the', 'french', 'by', 'katherine', 'woods', 'once', 'when', 'i', 'was', 'six', 'years', 'old', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'called', 'true', 'stories', 'from', 'nature', 'about', 'the', 'primeval', 'forest', 'it', 'was', 'a', 'picture', 'of', 'a', 'boa', 'constrictor', 'in', 'the', 'act', 'of', 'swallowing', 'an', 'animal', 'here', 'is', 'a', 'copy', 'of', 'the', 'drawing', 'in', 'the', 'book', 'it', 'said', 'boa', 'constrictors', 'swallow', 'their', 'prey', 'whole', 'without', 'chewing', 'it', 'after', 'that', 'they', 'are', 'not', 'able', 'to', 'move', 'and', 'they', 'sleep', 'through', 'the', 'six', 'months', 'that', 'they', 'need', 'for', 'digestion', 'i', 'pondered']\n",
      "16753\n"
     ]
    }
   ],
   "source": [
    "# apply the function to emmawords\n",
    "alphaprincewords = [w for w in princewords if not alpha_filter(w)]\n",
    "print(alphaprincewords[:100])\n",
    "print(len(alphaprincewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c983dcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STOPWORDS\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5602f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7085\n"
     ]
    }
   ],
   "source": [
    "stoppedprincewords = [w for w in alphaprincewords if not w in stopwords]\n",
    "print(len(stoppedprincewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84cd0e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('little', 258)\n",
      "('said', 195)\n",
      "('prince', 185)\n",
      "('one', 133)\n",
      "('planet', 69)\n",
      "('like', 58)\n",
      "('flower', 55)\n",
      "('good', 49)\n",
      "('time', 45)\n",
      "('sheep', 43)\n"
     ]
    }
   ],
   "source": [
    "## FREQUENCY #2\n",
    "princedist = FreqDist(stoppedprincewords)\n",
    "princeitems = princedist.most_common(10)\n",
    "for item in princeitems:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12d9f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('little', 0.03641496118560339)\n",
      "('said', 0.027522935779816515)\n",
      "('prince', 0.02611150317572336)\n",
      "('one', 0.018772053634438957)\n",
      "('planet', 0.009738884968242767)\n",
      "('like', 0.008186309103740297)\n",
      "('flower', 0.0077628793225123505)\n",
      "('good', 0.006916019760056458)\n",
      "('time', 0.006351446718419196)\n",
      "('sheep', 0.006069160197600565)\n"
     ]
    }
   ],
   "source": [
    "#normalized frequency\n",
    "numwords2 = len(stoppedprincewords)\n",
    "topkeys2norm=[(word, freq/numwords2) for (word,freq) in princeitems]\n",
    "for pair in topkeys2norm:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f97aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85b4a940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'little'), ('little', 'prince'), ('prince', 'written'), ('written', 'and'), ('and', 'illustrated'), ('illustrated', 'by'), ('by', 'antoine'), ('antoine', 'de'), ('de', 'saint'), ('saint', 'exupéry'), ('exupéry', 'translated'), ('translated', 'from'), ('from', 'the'), ('the', 'french'), ('french', 'by'), ('by', 'katherine'), ('katherine', 'woods'), ('woods', 'once'), ('once', 'when'), ('when', 'i')]\n"
     ]
    }
   ],
   "source": [
    "## BIGRAMS\n",
    "# use \"words\", don't remove stopwords and symbols yet\n",
    "princebigrams = list(nltk.bigrams(princewords))\n",
    "print(princebigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8f14045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b73f04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(princewords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eb033cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('.', '.'), 0.013303141805830738)\n",
      "(('.', '``'), 0.012878573450325502)\n",
      "(('.', \"''\"), 0.010708557411076517)\n",
      "((',', \"''\"), 0.0093405038211152)\n",
      "((\"''\", '``'), 0.009293329559392395)\n",
      "(('little', 'prince'), 0.008680064156995944)\n",
      "(('the', 'little'), 0.008491367110104727)\n",
      "(('?', \"''\"), 0.006038305500518917)\n",
      "((',', 'and'), 0.005000471742617228)\n",
      "(('.', 'i'), 0.0046230776488347955)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:10]:\n",
    "    print(bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f8de76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('little', 'prince'), 0.008680064156995944)\n",
      "(('the', 'little'), 0.008491367110104727)\n",
      "(('it', 'is'), 0.004528729125389187)\n",
      "(('said', 'the'), 0.004387206340220775)\n",
      "(('of', 'the'), 0.0032550240588734786)\n",
      "(('in', 'the'), 0.0029248042268138503)\n",
      "(('i', 'have'), 0.0027832814416454384)\n",
      "(('i', 'am'), 0.002500235871308614)\n",
      "(('that', 'is'), 0.002170016039248986)\n",
      "(('said', 'to'), 0.0020284932540805736)\n",
      "(('and', 'i'), 0.0018397962071893576)\n",
      "(('he', 'said'), 0.0018397962071893576)\n",
      "(('i', 'was'), 0.0018397962071893576)\n",
      "(('to', 'me'), 0.0017926219454665535)\n",
      "(('a', 'little'), 0.0016982734220209455)\n",
      "(('to', 'the'), 0.0016039248985753372)\n",
      "(('it', 'was'), 0.0015567506368525334)\n",
      "(('that', 'i'), 0.0015567506368525334)\n",
      "(('and', 'the'), 0.0015095763751297292)\n",
      "(('did', 'not'), 0.0015095763751297292)\n",
      "(('the', 'stars'), 0.0015095763751297292)\n",
      "(('of', 'a'), 0.0014624021134069251)\n",
      "(('i', 'shall'), 0.001415227851684121)\n",
      "(('is', 'a'), 0.0013680535899613171)\n",
      "(('you', 'are'), 0.0013680535899613171)\n",
      "(('all', 'the'), 0.001320879328238513)\n",
      "(('he', 'was'), 0.001320879328238513)\n",
      "(('the', 'fox'), 0.001320879328238513)\n",
      "(('the', 'king'), 0.001273705066515709)\n",
      "(('and', 'he'), 0.001226530804792905)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ff7a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('little', 'prince'), 0.008680064156995944)\n",
      "(('good', 'morning'), 0.0009906594961788847)\n",
      "(('conceited', 'man'), 0.00047174261722804036)\n",
      "(('long', 'time'), 0.00042456835550523637)\n",
      "(('boa', 'constrictor'), 0.0003773940937824323)\n",
      "(('one', 'day'), 0.0003773940937824323)\n",
      "(('prince', 'said'), 0.0003773940937824323)\n",
      "(('drawing', 'number'), 0.00033021983205962826)\n",
      "(('glass', 'globe'), 0.00033021983205962826)\n",
      "(('little', 'man'), 0.00033021983205962826)\n",
      "(('said', 'nothing'), 0.00033021983205962826)\n",
      "(('far', 'away'), 0.0002830455703368242)\n",
      "(('fresh', 'water'), 0.0002830455703368242)\n",
      "(('one', 'never'), 0.0002830455703368242)\n",
      "(('prince', 'went'), 0.0002830455703368242)\n",
      "(('went', 'away'), 0.0002830455703368242)\n",
      "(('boa', 'constrictors'), 0.00023587130861402018)\n",
      "(('little', 'bushes'), 0.00023587130861402018)\n",
      "(('never', 'knows'), 0.00023587130861402018)\n",
      "(('shall', 'look'), 0.00023587130861402018)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "776c5e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('$', '20,000'), 14.371640534611808)\n",
      "((\"'ve\", 'finished'), 14.371640534611808)\n",
      "(('7,500,000', 'tipplers'), 14.371640534611808)\n",
      "(('7000', 'geographers'), 14.371640534611808)\n",
      "(('900,000', 'businessmen'), 14.371640534611808)\n",
      "(('antoine', 'de'), 14.371640534611808)\n",
      "(('astronomical', 'congress'), 14.371640534611808)\n",
      "(('billion', 'inhabitants'), 14.371640534611808)\n",
      "(('bulky', 'almanac'), 14.371640534611808)\n",
      "(('caravan', 'passing'), 14.371640534611808)\n",
      "(('considerable', 'risks'), 14.371640534611808)\n",
      "(('de', 'saint'), 14.371640534611808)\n",
      "(('earliest', 'youth'), 14.371640534611808)\n",
      "(('exact', 'spot'), 14.371640534611808)\n",
      "(('extra', 'task'), 14.371640534611808)\n",
      "(('exupéry', 'translated'), 14.371640534611808)\n",
      "(('faded', 'peacefully'), 14.371640534611808)\n",
      "(('fairly', 'starting'), 14.371640534611808)\n",
      "(('familiar', 'tasks'), 14.371640534611808)\n",
      "(('field', 'poppies'), 14.371640534611808)\n"
     ]
    }
   ],
   "source": [
    "### PMI\n",
    "finder3 = BigramCollocationFinder.from_words(princewords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fabe947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('glass', 'globe'), 11.564285612554205)\n",
      "(('boa', 'constrictor'), 10.671200816470717)\n",
      "(('boa', 'constrictors'), 10.671200816470717)\n",
      "(('thousand', 'miles'), 10.301251206720412)\n",
      "(('fresh', 'water'), 10.201715533169496)\n",
      "(('six', 'years'), 9.649174510140718)\n",
      "(('far', 'away'), 9.111112984388589)\n",
      "(('drawing', 'number'), 9.019124119891023)\n",
      "(('conceited', 'man'), 8.863845894413114)\n",
      "(('went', 'away'), 8.433041079275952)\n",
      "(('good', 'morning'), 8.195051802888486)\n",
      "(('never', 'knows'), 8.166091623438776)\n",
      "(('long', 'time'), 8.049712439724448)\n",
      "(('shall', 'look'), 6.706304617426634)\n",
      "(('little', 'bushes'), 6.360413279188556)\n",
      "(('little', 'prince'), 6.352593774729256)\n",
      "(('prince', 'went'), 5.425221574816652)\n",
      "(('one', 'day'), 5.3621617887237445)\n",
      "(('said', 'nothing'), 4.571665142919802)\n",
      "(('one', 'never'), 4.543768595213692)\n",
      "(('little', 'man'), 4.038485184301191)\n",
      "(('prince', 'said'), 2.232928760345887)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89eff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
